---
title: "Homework 25 Key"
author: "Erika Barthelmess"
date: "`r Sys.Date()`"
output: html_document
---

Homework 25 asks you to work through the second half of Chapter 5 of the GSWR book.

## 5.4 Introducing linear models
Now we move into something called "general linear models". They are a class of model that includes regression, multiple regression, ANOVA and ANCOVA. All are fundamentally linear models.

Don't confuse a general linear model with a *generalized* linear model or GLM. 

## 5.5 Simple linear regression
Does plant growth rate vary with soil moisture content?

Prediction: more moisture will likely allow higher growth rates. Note that the predictor (explanatory) variable is quantitative and not categorical.

### 5.5.1 Getting a plotting the data.
We are using a dataset from the book called plant.growth.rate.csv.

Let's get going
```{r}
rm(list = ls())
library(dplyr)
library(ggplot2)
library(here)

plant_gr<-read.csv(here("Data", "plant.growth.rate.csv"))
```

Take a look at the data
```{r}
glimpse(plant_gr)
```
Two columns of numeric data. 

Let's start with a scatter plot:
```{r}
ggplot(plant_gr, aes(soil.moisture.content, plant.growth.rate))+
     geom_point()+
     ylab("Plant growth rate (mm/week)")+
     theme_bw()
```
### 5.5.2 Interpreting the figure: biological insight

We notice that the slope is positive. We can also guestimate the slope and intercept from the figure.
- Roughly speaking, the growth rate varies b/w 20 and 50 mm/week
- Roughly speaking, soil moisture varies between 0 and 2

Slope is rise/run, which in this case is about (50-20) = 30 for rise and 2 - 0 = 2 for run, so we get 30/2 = 15 as the slope. 

Eyeballing the plot, we would also guess that the y-intercept is somewhere between 15 and 20 mm/week. 

IT IS ALWAYS A GOOD IDEA TO EXAMINE YOUR DATA BEFORE THE ANALYSIS AND TO SEE IF YOU CAN APPROXIMATE SOME OF THE VALUES THAT WILL RESULT.

## 5.5.3 Making a simple linear regression happen

We use the `lm()` function...
```{r}
model_pgr <- lm(plant.growth.rate ~ soil.moisture.content, data = plant_gr)
```

Ok, the model has been fit. Before we look at the results, let's consider the assumptions.

We need to use the ggfortify package and the autoplot() function within it. The book suggests adding ggfortify at our top-level script from here on out.

```{r}
library(ggfortify)
autoplot(model_pgr, smooth.color = NA)
```
What does this all mean?
Top left - residuals vs. fitted:

Is a line appropriate to fit to the data (vs. a non-linear model)? - look for hump shapes or valleys. 

Top right - Normal Q-Q plot:
This evaluates the assumption that the residuals are normally distrubted. The dots are the residuals and the dashed line is the expected values under a normal distribtuion.  Basically, you want the dots to fall pretty close to the line (observed = expected).

Bottom left - Scale - location:
This evaluates the assumption of equal variance. The y-axis is a standardized (all positive) indicator of the variation. Linear models assume that the variance is constant over all predicted values of the response variable. There should be no pattern. (There might be a pattern, if, for instance, the variance increases with the mean as it might with count data).

Bottom right - Residuals vs. leverage:
This plot evaluates leverage, a tool that helps to detect influential data points and that also detects outliers. 

What does `smooth.color = NA` do?  In the absence of this argument, the default presentation would be a wiggly line fitted by the regression. The NA suppresses that line.

### 5.5.5 Now the interpretation

Now that we know that our data meet the assumptions of a linear regression, we can look at and interpret the model.

We use two tools that we will use for every general (and generalized) model here on out: `anova()` and `summary()`.

`anova()` does not perform an ANOVA. Instead, it produces a classic anova table, the sums-of-squares table including the F-statistic, which is the ratio of variance explained by the explanatory variable  to the leftover variance. As well, it produces an estimate of R^2 and adjusted R^2.

`summary()` is less confusing. It produces a table witht he estimates of the coefficients of the line that is the model: an intercept and a slope.  

Take a look:

```{r}
anova(model_pgr)
```
And the summary table:
```{r}
summary(model_pgr)
```
### 5.5.6 From stats back to figure
Now let's make a figure that shows off our relationship in light of our statistical results.

```{r}
ggplot(plant_gr, aes(soil.moisture.content, plant.growth.rate))+
     geom_point()+
     geom_smooth(method = "lm")+
     ylab("Plant growth rate (mm/week)")+
     theme_bw()
```
We can see that the `geom_smooth()` call allowed the computer to add the fitted values and the standard error of the fit to a figure.

Don't expect `geom_smooth()` to work correctly for more complex models. 

## 5.6. Analysis of variance: the one-way ANOVA
In a one way ANOVA, the predictor (explanatory) variable is a factor (categorical) rather than a numeric variable.

We'll use a dataset with **Daphnia** and their parasites. 

### 5.6.1. Getting and plotting the data

The dataset is called daphniagrowth.csv. Let's clean things up and read it in
```{r}
rm(list = ls()) #clear from R any of the code we've already been working on
library(ggfortify)
library(dplyr)
library(ggplot2)
library(here)
```
Pull in the data
```{r}
daphnia <-read.csv(here("Data", "Daphniagrowth.csv"))
daphnia$parasite<-as.factor(daphnia$parasite)
```
Our question has 2 parts: 1) in general, do parasites alter growth rates and 2) if so, whether each parasite reduces growth rate relative to the control.

Let's make a box and whisker plot of growth as a function of parasite type.

```{r}
ggplot(daphnia, aes(parasite, growth.rate))+
     geom_boxplot()+
     theme_bw()
```

Now let's flip the coordinates to keep names from overlapping

```{r}
ggplot(daphnia, aes(parasite, growth.rate))+
     geom_boxplot()+
     coord_flip()+
     theme_bw()
```
There appears to be a likely overall paraste effect and an ordering of the effect of parasite type on growth rate such that P. ramosa < M. bicuspidata < P. perplexa < control

We can also estimate the average growth rate for each treatment:
- control approx 1.2, P. perplexa c. 1.1, M. bicuspidata c. 0.8 and P. ramosa c. 0.55.

- we can also figure out the degrees of freedom for the treatment and for error. Sample size minus the number of parameters we are estimating = 4 levels - 1 = 3 for the effect of parasites and 4 means from 40 samples = 36 for the error degrees of freedom.

### 5.6.2 Construct the ANOVA 
Again we use lm() to construct our model
```{r}
model_grow <- lm(growth.rate ~ parasite, data = daphnia)
```

### 5.6.3 Check the assumptions
The assumptions in a one-way ANOVA and linear regression are the same, so we can use the same method with ggfortify and autoplot().

```{r}
autoplot(model_grow, smooth.color = NA)
```

These look fine. Let's move on.

### Making an inference from a one-way ANOVA
The anova() call will answer our first question of whether there is a general effect of the parasite treatment on daphnia growth rates.

```{r}
anova(model_grow)
```

The null hypothesis is that all of the groups have the same mean. The F-statistic quantifies how likely that is to be true. There is a very very small chance (p = 0.0000257) of obtaining this F statistic when the means are the same. Also, the F statistic is the ratio of the between-group variance to the within group variance. As the between-group variance increases, so does the F value.

Our second question was what are the effects of the different parasites. There are different ways to answer this question - we will look at one that helps us understand how R presents coefficients of linear models with categorical explantory variables.  

### Treatment contrasts (i.e. how we answer our 2nd question)
Let's start by getting the summary table
```{r}
summary(model_grow)
```
We can look at the help for contr.treatment to see how R deals with contrasts

```{r}
?contr.treatment
```
Ok - so how do we interpret that contrast table?

There are 4 rows in the table, and the first is labeled Intercept. Below it are the names of the three parasite treatments. 

Pay attention to the alphabet with understanding how R presents coefficient contrasts. It defaults to presenting results in alphabetical order.

The alphebetical ordering would be control < M. bicuspidata < P. perplexa < P. ramosa. Thus, the intercept in this case represents the control. It represents the first level, alphabetically, of the treatment levels, which, in this case, is the word "control" and thus the control is represented by the intercept.

Treatment contrasts then represent the differences between the refrence level (in this case the control, but whatever the intercept represents) and the other levels. So, the numbers in the estimate column associated with each parasite are the difference between the mean of the control group and the mean of the specified parasite. 

We can get the actual means using a group_by and summarize option, and, if we wanted, we could calculate the contrasts ourselves.

```{r}
sumDat <- daphnia %>% group_by(parasite) %>% summarise(meanGR = mean(growth.rate))
```

Because the control happens to be the reference group, that means the p-values are actually useful, because they tell us if there is a significant difference between each treatment and the control.

Now let's make a final figure, something like figure 5.11, using both the daphnia and the sumDat data frames to get it to look good.

```{r}
ggplot(daphnia, aes(parasite, growth.rate, color = parasite))+
     geom_point(size = 3)+
     geom_point(data = sumDat, aes(parasite, meanGR, fill = parasite), shape = 23, size = 5)+
     coord_flip()+
     theme_bw()
```

